{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action Project Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members: Abhi Gandhi, Jeff Won, Shashank Saurav, Shengebo Zhang, Faraz Khoshbakhtian  \n",
    "\n",
    "\n",
    "Main contributor to this document: Shengbo Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document outlines the steps taken by our group to approach the Mechanisms of Action competition. This document presents are original approach whereas another document presents the challanger approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "### This part is to run pyspark locally\n",
    "import findspark  # Get rid of this in DataBricks\n",
    "# findspark.init('/opt/spark-3.0.1')  # Get rid of this in DataBricks #faraz: you can remove the parameter. it only worked like this for me\n",
    "findspark.init()\n",
    "########################################\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F \n",
    "from pyspark.sql.functions import explode, col, udf, mean as _mean, stddev as _stddev, log, log10, sqrt\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from scv import StratifiedCrossValidator  # This file is for crossvalidation. Please see scv.py for more information\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeting up spark, contexts and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.dynamicAllocation.minExecutors', '1'), ('spark.dynamicAllocation.initialExecutors', '2'), ('spark.driver.port', '39545'), ('spark.executor.id', 'driver'), ('spark.driver.host', '192.168.176.164'), ('spark.rdd.compress', 'True'), ('spark.driver.memory', '8g'), ('spark.serializer.objectStreamReset', '100'), ('spark.cores.max', '8'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.dynamicAllocation.maxExecutors', '8'), ('spark.executor.cores', '8'), ('spark.app.name', 'proj'), ('spark.app.id', 'local-1608141748744'), ('spark.ui.showConsoleProgress', 'true'), ('spark.executor.memory', '50g')]\n"
     ]
    }
   ],
   "source": [
    "config = SparkConf().setAll([('spark.executor.memory', '50g'), ('spark.executor.cores', '8'), ('spark.cores.max', '8'), ('spark.driver.memory','8g')])\n",
    "config.setAppName(\"proj\")\n",
    "config.set(\"spark.dynamicAllocation.minExecutors\", \"1\");\n",
    "config.set(\"spark.dynamicAllocation.maxExecutors\", \"8\");\n",
    "config.set(\"spark.dynamicAllocation.initialExecutors\", \"2\"); # the number must be between the min and max\n",
    "sc = SparkContext(conf=config)  # start a new sc with the current config\n",
    "spark = SparkSession(sc)\n",
    "sqlc=SQLContext(sc)\n",
    "print(sc.getConf().getAll())  # print all the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.getMaxIter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Preprocessing the Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Joining dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to read the features and labels for the training data, get rid of controll cases and join all the training data into a singular Spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for being able to store the data in github and concatenation on local computer\n",
    "!cat train_features_*.csv > train_feats.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Features Dataset\n",
    "df_train = spark.read.csv('train_feats.csv', header='true', inferSchema= 'true')   # path in HDFS file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels Dataset\n",
    "df_label = spark.read.csv('train_targets_scored.csv', header='true', inferSchema= 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all data together\n",
    "df = df_train.join(df_label, on=['sig_id'], how='left_outer')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the control cases since the test data also comes with control/case flag\n",
    "df = df.filter(df.cp_type == 'trt_cp')\n",
    "df = df.drop('cp_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding for Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need to **One-Hot Encode** our categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String indexer for cp_dose\n",
    "indexer = StringIndexer(inputCol=\"cp_dose\", outputCol=\"cp_dose_cat\")\n",
    "# index cp_dose in data\n",
    "df1 = indexer.fit(df).transform(df)\n",
    "\n",
    "# String indexer for cp_time\n",
    "indexer = StringIndexer(inputCol=\"cp_time\", outputCol=\"cp_time_cat\")\n",
    "# index cp_time in data\n",
    "df1 = indexer.fit(df1).transform(df1)\n",
    "df1 = df1.drop('cp_dose')\n",
    "df1 = df1.drop('cp_time')\n",
    "\n",
    "# One-hot enocder \n",
    "encoder = OneHotEncoder(inputCols=[\"cp_time_cat\", \"cp_dose_cat\"],\n",
    "                        outputCols=[\"cp_time_onehot\", \"cp_dose_onehot\"])\n",
    "\n",
    "model = encoder.fit(df1)\n",
    "df1 = model.transform(df1)\n",
    "\n",
    "# Keeping n-1 dummy variables for each feature. (dummy variables have degree of fredom n-1)\n",
    "df1 = df1.withColumn(\"cp_time_cols\", vector_to_array(\"cp_time_onehot\")).select(df1.columns + [col(\"cp_time_cols\")[i] for i in range(2)])\n",
    "df1 = df1.withColumn(\"cp_dose_cols\", vector_to_array(\"cp_dose_onehot\")).select(df1.columns + [col(\"cp_dose_cols\")[i] for i in range(1)])\n",
    "\n",
    "# drop leftover cols\n",
    "df1 = df1.drop('cp_dose_cat',\n",
    " 'cp_time_cat',\n",
    " 'cp_time_onehot',\n",
    " 'cp_dose_onehot',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we create some features that describes the statistics of each row. We look at the row-wise min, max, mean, standard deviation for gene and cell information. We also use KMeans clustering to classify the data into 3 cluster classes based on Euclidean distance and use the cluster results as an additional engineered feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_feature_names = [name for name in df1.columns if 'g-' in name]\n",
    "cell_feature_names =  [name for name in df1.columns if 'c-' in name]\n",
    "\n",
    "df2 = df1.withColumn(\"gene_max\", F.greatest(*gene_feature_names))\n",
    "df2 = df2.withColumn(\"gene_min\", F.least(*gene_feature_names))\n",
    "df2 = df2.withColumn(\"cell_max\", F.greatest(*cell_feature_names))\n",
    "df2 = df2.withColumn(\"cell_min\", F.least(*cell_feature_names))\n",
    "\n",
    "\n",
    "df2 = df2.withColumn(\"gene_mean\", reduce(lambda x,y: x+y, (col(x) for x in gene_feature_names)) / len(gene_feature_names))\n",
    "df2 = df2.withColumn(\"cell_mean\", reduce(lambda x,y: x+y, (col(x) for x in cell_feature_names)) / len(cell_feature_names))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Purpose Feature Selection Based on Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our initial step for feature selection we use correlation meassure to reduce the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_corr_features(df, gene_feature_names, cell_feature_names ):  # This function will be referenced by train_individual_label function below \n",
    "    \n",
    "    # Keeping track of the feature names\n",
    "    feature_columns = gene_feature_names + cell_feature_names \n",
    "\n",
    "    # Creating the feature vector\n",
    "    vectorAssembler = VectorAssembler(inputCols = feature_columns, outputCol = 'feats' )\n",
    "    feature_vector = vectorAssembler.transform(df).select(\"feats\")\n",
    "\n",
    "    # Computing the correlations with pySpark\n",
    "    corr_matrix = Correlation.corr(feature_vector, \"feats\").head()[0]\n",
    "\n",
    "    # Convert the correlation desne matrix and apply mask and to get the indicies where high correlations are observed\n",
    "    # In here, I convert the correlation matrix to numpy, and then use numpy's mask to obtain the lower traingle of the\n",
    "    # matrix. I used numpy becasue pyspark does not have mask.\n",
    "\n",
    "    # Detection highly correlated features\n",
    "    corr_Array = corr_matrix.toArray()\n",
    "    masked_corr = np.ma.masked_where(np.triu(np.ones_like(corr_Array, dtype=bool)), corr_Array, copy=True)  \n",
    "    idx_high_corr_feats = set(np.argwhere(abs(masked_corr) > 0.60)[:,0])  # Set threshold to 90%\n",
    "    # Identify the column to drop \n",
    "    features_to_drop = np.array(feature_columns)[list(idx_high_corr_feats)].tolist()\n",
    "\n",
    "\n",
    "    return features_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for Mechanisms of Action is formally considred a Multi-label classification problem. We are employing the Binary-Relevance approach for the problem at hand. For each of the possible binary labels we first use a **Random Forrest CLassifier** to achive another level of feature selection based on the feature importance meassure. Subsequently, we train one **logistic regression** model and a **naive bayes** model for each label.\n",
    "\n",
    "We have use upsampling the minority class and downsampling the majority class to overcome issues of imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fucntion train_test_vectorize packs all the features into a single vector. This function was referred to in the train_individual_label function.\n",
    "\n",
    "def train_test_vectorize(train, test, drop_features,  label_name):\n",
    "    train  = train.drop(*drop_features)\n",
    "    test = test.drop(*drop_features)\n",
    "    # Getting the final feature set\n",
    "    final_feature_names = list(set(train.columns) - set((label_name, )))\n",
    "\n",
    "    # Create Feature vector\n",
    "    vectorAssembler = VectorAssembler(inputCols = final_feature_names, outputCol = 'features' )\n",
    "\n",
    "    # drop all unnecessary features\n",
    "    train = vectorAssembler.transform(train).drop(*final_feature_names)\n",
    "    test = vectorAssembler.transform(test).drop(*final_feature_names)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train = train.select(F.col(label_name).alias('label'), F.col('features'))  # Just renaming these columns\n",
    "    test = test.select(F.col(label_name).alias('label'), F.col('features')) # Just renaming these columns\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_label_names = df_label.columns\n",
    "list_of_feature_names = list(set(df2.columns) - set(df_label.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.cache()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for the tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function is responsible for running our ml pipeline\n",
    "\n",
    "#df is the train dataset, label_name is the label we want to do the training on\n",
    "\n",
    "def train_individual_label(df, label_name, seed = 43, ):\n",
    "\n",
    "    try:\n",
    "    # we need at least 2 positive instances for this particular label_name\n",
    "        if df.filter(df[label_name] == 1).count() >= 2:   # The model taining is only performed for labels with more than two activated samples\n",
    "\n",
    "            # dataframe consisting only of the train features and the label name\n",
    "            temp_df = df.select(*list_of_feature_names, label_name)\n",
    "\n",
    "            # stratify split of the dataframe for train-test split\n",
    "            fractions = {1: 0.8, 0: 0.8}\n",
    "            train_df = temp_df.stat.sampleBy(label_name, fractions, )\n",
    "            test_df =  temp_df.subtract(train_df)\n",
    "            \n",
    "            high_corr_names = get_high_corr_features(train_df, gene_feature_names, cell_feature_names )\n",
    "            train_df, test_df  =  train_test_vectorize(train_df, test_df, high_corr_names,  label_name)\n",
    "\n",
    "    \n",
    "\n",
    "            # another layer of feature selection using random forrest before training the ml models\n",
    "            clf = RandomForestClassifier(numTrees=20, maxDepth=5, featuresCol='features',  seed=42)\n",
    "            model = clf.fit(train_df)\n",
    "            feature_importance = model.featureImportances.toArray()\n",
    "\n",
    "            # indeces of only the top 5% of features\n",
    "            important_feature_idx = feature_importance.argsort()[-int(0.05 * len(feature_importance)):]  \n",
    "\n",
    "\n",
    "\n",
    "            # Now, after getting the index, filter the feature vector based on the above feature importance index\n",
    "            slicer = VectorSlicer(inputCol=\"features\", outputCol=\"sub_features\", indices=important_feature_idx)\n",
    "            final_train_df_sub_feats =  slicer.transform(train_df).drop('features')\n",
    "            final_test_df_sub_feats = slicer.transform(test_df).drop('features')\n",
    "\n",
    "            final_train_df_sub_feats = final_train_df_sub_feats\\\n",
    "                                 .select(F.col('label'), F.col('sub_features').alias('features'))  # Just renaming these columns\n",
    "\n",
    "            final_test_df_sub_feats = final_test_df_sub_feats\\\n",
    "                                 .select(F.col('label'), F.col('sub_features').alias('features'))  # Just renaming these columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Use CV to train a logistic regression model\n",
    "            lr = LogisticRegression(maxIter=10)\n",
    "            lr_paramGrid = ParamGridBuilder() \\\n",
    "                            .addGrid(lr.regParam, [ 0.1, 0.01]) \\\n",
    "                            .addGrid(lr.elasticNetParam, [1,  0])\\\n",
    "                            .build()\n",
    "\n",
    "\n",
    "            lr_evaluator = MulticlassClassificationEvaluator(metricName='logLoss')\n",
    "            lr_crossval = StratifiedCrossValidator(estimator=lr,\n",
    "                                  estimatorParamMaps=lr_paramGrid,\n",
    "                                  evaluator=lr_evaluator,\n",
    "                                  numFolds=3,\n",
    "                                  parallelism=4)  \n",
    "\n",
    "            lr_cvModel = lr_crossval.fit(final_train_df_sub_feats)\n",
    "\n",
    "            lr_prediction_df = lr_cvModel.transform(final_test_df_sub_feats)\n",
    "\n",
    "            ### In the code below, we are saving the trained data for future use.   ####\n",
    "\n",
    "            lr_cvModel.save(f\"./logistics_new/{label_name}.model\")\n",
    "            lr_prediction_df.write.save(f\"./logistics_new/{label_name}_prediction_df.parquet\", format=\"parquet\")\n",
    "            final_train_df_sub_feats.write.save(f\"./logistics_new/{label_name}_train_df.parquet\", format=\"parquet\")\n",
    "\n",
    "            lr_log_loss = lr_evaluator.evaluate(lr_prediction_df)\n",
    "\n",
    "            with open(f\"./logistics_new/log.log\", 'a') as f:\n",
    "                f.write('logistics, '+ str(label_name) + ', ' + str(lr_log_loss) + '\\n') \n",
    "\n",
    "\n",
    "        else:   # \n",
    "            with open(f\"./logistics_new/log.log\", 'a') as f:\n",
    "                f.write('logistics, '+ str(label_name) + ', ' + 'False' + '\\n') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e: # log the error as well; these are to be retrained later using a differnt seed later\n",
    "        with open(f\"./logistics_new/log.log\", 'a') as f:\n",
    "            f.write('logistics, '+ str(label_name) + ', ' + 'errored' + '\\n') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for the untuned model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is responsible for running our ml pipeline\n",
    "\n",
    "#df is the train dataset, label_name is the label we want to do the training on\n",
    "def train_individual_label_baseline(df, label_name, seed = 42,):\n",
    "    try:\n",
    "    \n",
    "    # we need at least 2 positive instances for this particular label_name\n",
    "        if df.filter(df[label_name] == 1).count() >= 2:  # Only the labels with activation numbers greater than 2 will be trained\n",
    "\n",
    "            # dataframe consisting only of the train features and the label name\n",
    "#             temp_df = df.select('feats', label_name)\n",
    "            temp_df = df.select(*list_of_feature_names, label_name)\n",
    "\n",
    "            # stratify split of the dataframe for train-test split\n",
    "            fractions = {1: 0.8, 0: 0.8}\n",
    "            train_df = temp_df.stat.sampleBy(label_name, fractions, seed, )\n",
    "            test_df =  temp_df.subtract(train_df)\n",
    "\n",
    "\n",
    "            \n",
    "            high_corr_names = get_high_corr_features(train_df, gene_feature_names, cell_feature_names )\n",
    "            train_df, test_df  =  train_test_vectorize(train_df, test_df, high_corr_names,  label_name)\n",
    "\n",
    "            ################## over/down samping  ##################\n",
    "            \n",
    "            activation_samples = train_df.filter(train_df['label'] == 1)\n",
    "            non_activation_samples = train_df.filter(train_df['label'] == 0)\n",
    "            ratio = activation_samples.count() / non_activation_samples.count()\n",
    "\n",
    "            default_down_sample_ratio = 0.5  # This can be changed, but for now,i am just setting it as 0.5\n",
    "\n",
    "            upsample_ratio = default_down_sample_ratio / ratio\n",
    "\n",
    "            activation_samples_up = activation_samples.sample(True, upsample_ratio, 42)   # Upsample the activation samples\n",
    "\n",
    "            non_activation_samples_down = non_activation_samples.sample(True, default_down_sample_ratio, 42)  # Meanwhile, downsampling the non-activated samples \n",
    "\n",
    "\n",
    "            train_df = activation_samples_up.union(non_activation_samples_down).orderBy(F.rand())\n",
    "            \n",
    "            \n",
    "            ###########################################\n",
    "\n",
    "\n",
    "            # another layer of feature selection using random forrest before training the ml models\n",
    "            clf = RandomForestClassifier(numTrees=20, maxDepth=5, featuresCol='features',  seed=42)\n",
    "            model = clf.fit(train_df)\n",
    "            feature_importance = model.featureImportances.toArray()\n",
    "\n",
    "            # indeces of only the top 5% of features\n",
    "            important_feature_idx = feature_importance.argsort()[-int(0.05 * len(feature_importance)):]  \n",
    "\n",
    "\n",
    "\n",
    "            # Now, after getting the index, filter the feature vector based on the above feature importance index\n",
    "            slicer = VectorSlicer(inputCol=\"features\", outputCol=\"sub_features\", indices=important_feature_idx)\n",
    "            final_train_df_sub_feats =  slicer.transform(train_df).drop('features')\n",
    "            final_test_df_sub_feats = slicer.transform(test_df).drop('features')\n",
    "\n",
    "            final_train_df_sub_feats = final_train_df_sub_feats\\\n",
    "                                 .select(F.col('label'), F.col('sub_features').alias('features'))  # Just renaming these columns\n",
    "\n",
    "            final_test_df_sub_feats = final_test_df_sub_feats\\\n",
    "                                 .select(F.col('label'), F.col('sub_features').alias('features'))  # Just renaming these columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Use CV to train a logistic regression model\n",
    "            lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "\n",
    "\n",
    "            lr_evaluator = MulticlassClassificationEvaluator(metricName='logLoss')\n",
    "\n",
    "\n",
    "            lr_Model = lr.fit(final_train_df_sub_feats)\n",
    "\n",
    "            lr_prediction_df = lr_Model.transform(final_test_df_sub_feats)\n",
    "\n",
    "            lr_Model.save(f\"./logistics-baseline-new/{label_name}.model\")\n",
    "            lr_prediction_df.write.save(f\"./logistics-baseline-new/{label_name}_prediction_df.parquet\", format=\"parquet\")\n",
    "            final_train_df_sub_feats.write.save(f\"./logistics-baseline-new/{label_name}_train_df.parquet\", format=\"parquet\")\n",
    "\n",
    "            lr_log_loss = lr_evaluator.evaluate(lr_prediction_df)\n",
    "\n",
    "            with open(f\"./logistics-baseline-new/log.log\", 'a') as f:\n",
    "                f.write('logistics, '+ str(label_name) + ', ' + str(lr_log_loss) + '\\n') \n",
    "\n",
    "        else:\n",
    "            with open(f\"./logistics-baseline-new/log.log\", 'a') as f:\n",
    "                f.write('logistics, '+ str(label_name) + ', ' + 'False' + '\\n') \n",
    "         \n",
    "\n",
    "    except:\n",
    "        with open(f\"./logistics-baseline-new/log.log\", 'a') as f:\n",
    "            f.write('logistics, '+ str(label_name) + ', ' + 'errored' + '\\n') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below  runs the `train_individual_label` function for each label, to train the **tuned** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in tqdm(df_label.columns[1:]):\n",
    "    if not os.path.exists(f'./logistics_new/{name}.model'):\n",
    "        train_individual_label(df2,  name,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below  runs the `train_individual_label_baseline` function for each label, to train the **untuned** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in tqdm(df_label.columns[1:]):\n",
    "    if not os.path.exists(f'./logistics_new/{name}.model'):\n",
    "        train_individual_label_baseline(df2,  name, )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
