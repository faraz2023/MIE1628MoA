{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: applying window function was attampted, but not applied to the final models.\n",
    "\n",
    "Main contributor: Shengbo Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import findspark  # Get rid of this in DataBricks\n",
    "findspark.init()  # Get rid of this in DataBricks\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F \n",
    "from pyspark.sql.functions import explode, col, udf, mean as _mean, stddev as _stddev, log, log10\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.classification import GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv('train_feats.csv', header='true', inferSchema= 'true')   # path in HDFS file system\n",
    "df_label = spark.read.csv('train_targets_scored.csv', header='true', inferSchema= 'true')\n",
    "df = df_train.join(df_label, on=['sig_id'], how='left_outer')  # Jjoin them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sub_df = df2.select(*gene_feature_names)\n",
    "gene_sub_df_T = spark.createDataFrame(gene_sub_df.toPandas().T)\n",
    "\n",
    "w = Window.rowsBetween(-10,0)\n",
    "\n",
    "\n",
    "gene_sub_df_T_roll = gene_sub_df_T.select(\n",
    "    '*', \n",
    "    *( F.avg(i).over(w).alias(i + '_roll') for i in gene_sub_df_T.columns)\n",
    ").drop(*gene_sub_df_T.columns)  # apply rolling average transformation for each sample\n",
    "gene_rolled = spark.createDataFrame(gene_sub_df_T_roll.toPandas().T)\n",
    "\n",
    "gene_rolled = gene_rolled.select([col(c).alias('g_' + c + '_rolled') for c in gene_rolled.columns])\\\n",
    "                                .drop(*gene_rolled.columns)  # just renameing the columns... that's all\n",
    "\n",
    "\n",
    "window = Window.orderBy(F.col('monotonically_increasing_id'))\n",
    "gene_rolled = gene_rolled.withColumn(\"monotonically_increasing_id\", F.monotonically_increasing_id())\\\n",
    "                        .withColumn('row_number2', F.row_number().over(window))\\\n",
    "                        .drop('monotonically_increasing_id')\n",
    "\n",
    "gene_rolled.write.parquet('gene_rolled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
